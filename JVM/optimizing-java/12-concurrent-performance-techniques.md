*The Free Lunch Is Over*

- 이제는 기술력 발전에 기대기보다는 성능 분석의 새 시대를 맞이해야 한다
- 멀티코어 프로세서가 일반화한 시대
- 여러 프로세서 코어를 십분 활용할 수 있는 JVM 애플리케이션도 멀티코어 혜택을 누릴 수 있음
- 이번 장에서는 자바 동시성의 기본을 다룰 것
- 후속 학습은 『자바 병렬 프로그래밍』 등의 도서를 읽어보자

## 1. 병렬성이란?

**암달의 법칙**

```
T(N) = S + (1/N) * (T - S)
```

- T(N): N개의 프로세서를 사용할 때 걸리는 총 소요 시간
- S: 순차 실행 파트
- T - S: 병렬 실행 파트
- 프로세서를 무한히 증가시켜도 총 소요 시간은 S에 수렴

> 정확한 프로그램을 작성하는 일은 어렵습니다.  
> 정확한 동시 프로그램을 작성하는 건 훨씬 더 어렵습니다.  
> 아무래도 순차 프로그램보다 동시 프로그램이 잘못될 가능성이 더 크기 때문이죠.
>
> ⎯ 『자바 병렬 프로그래밍』

### 1.1 자바 동시성 기초

- 버그 재연이 어려움
  - *테스트는 버그가 있다는 사실을 밝히지만, 버그가 없다는 사실을 밝히지는 않는다*
- 자바 5 이전에는 `syncronized` 키워드를 사용하여 동시성을 다룸
  - 신중히 사용해야 하며, 잘못 사용하면 오히려 더 느려질 수 있음
- 처리율 향상을 위한 동시성 부여
  - 병렬화 작업을 진행할 때에는 복잡도가 늘어난 대가로 얻은 혜택을 충분히 입증할 수 있도록 성능 테스트가 수반되어야 한다

## 2. JMM의 이해

- 자바 1.0부터 있던 메모리 모델
- JSR(Java Specification Request) 133에서 개정되고 개선되어 자바 5와 함께 배포됨

JMM은 다음 질문에 답을 찾는 모델

- 두 코어가 같은 데이터를 액세스하면 어떻게 되는가?
- 언제 두 코어가 같은 데이터를 바라본다고 장담할 수 있는가?
- 메모리 캐시는 위 두 질문의 답에 어떤 영향을 미치는가?

JMM의 약속

- 순서에 관한 보장
- 여러 스레드에 대한 업데이트 가시성 보장
- 자바 플랫폼은 공유 상태를 어디서 액세스하든 약속한 내용을 반드시 이행

고수준에서 메모리 모델의 2가지 접근 방식

- **강한 메모리 모델** : 전체 코어가 항상 같은 값을 바라본다
- **약한 메모리 모델** : 코어마다 다른 값을 바라볼 수 있고 시점을 제어하는 특별한 캐시 규칙이 있다
- JMM은 약한 메모리 모델을 따름
  - 네이티브 수준에서 강한 메모리 모델을 지원하지 않는 경우 엄청난 이식 작업이 수반되기 때문

JMM의 기본 개념들

- **Happens-Before** : 한 이벤트는 무조건 다른 이벤트보다 먼저 발생한다
- **Synchronizes-With** : 이벤트가 객체 뷰를 메인 메모리와 동기화시킨다
- **All-If-Serial** : 실행 스레드 밖에서는 명령어가 순차 실행되는 것처럼 보인다
- **Release-Before-Acquire** : 한 스레드에 걸린 락을 다른 스레드가 그 락을 획득하기 전에 해제한다

자바의 스레드

- 객체 상태 정보를 스스로 들고 다님
- 스레드가 변경한 내용은 메모리로 곧장 반영
- 같은 데이터를 액세스하는 다른 액세스가 다시 메인 메모리를 읽는 구조

`syncronized` 키워드

- 모니터를 장악한 스레드의 로컬 뷰가 메인 메모리와 **Synchronizes-With** 되었다는 의미
- 동기화 메소드, 동기화 블록은 스레드가 반드시 동기를 맞춰야 할 접점에 해당
  - 다른 동기화 메소드/블록이 시작되기 전에 반드시 완료되어야 할 것

`synchronized` 락의 한계점들

- 락이 걸린 객체에서 일어나는 동기화 작업은 모두 균등하게 취급된다.
- 락 획득/해제는 반드시 메소드 수준이나 메소드 내부의 동기화 블록 안에서 이루어져야 한다.
- 락을 얻지 못한 스레드는 블로킹된다. 락을 얻지 못할 경우, 락을 얻어 처리를 계속하려고 시도하는 것조차 불가능하다.

JMM 정리

- 간결한 이해를 원한다면 [The JSR-133 Cookbook for Compiler Writers](https://gee.cs.oswego.edu/dl/jmm/cookbook.html) 읽어보기
- 자바 9부터 부분적으로나마 오늘날의 시스템 현실을 따라잡기 위해 확장되어 왔음
- 더 깊이 파고들고 싶다면 [Close Encounters of The Java Memory Model Kind](https://shipilev.net/blog/2016/close-encounters-of-jmm-kind/) 읽어보기

## 3. 동시성 라이브러리 구축

- JMM은 이해하기 어렵고, 인트린직 락킹의 유연성도 떨어짐
- 자바 5부터는 언어 수준 지원 기능에서 탈피해서 고급 동시성 라이브러리 툴을 자바 클래스 라이브러리의 일부로 표준화하려는 움직임이 확산되는 추세

`java.util.concurrent` 패키지

- 자바로 멀티 스레드 애플리케이션을 쉽게 개발할 수 있게 세심하게 설계된 라이브러리
- 조건에 가장 잘 맞는 추상화 수준을 선택해야 함
- 라이브러리 핵심 구성요소
  - 락, 세마포어
  - 아토믹스
  - 블로킹 큐
  - 래치
  - 실행자

CAS(Compare-And-Swap)

- 일부 라이브러리의 락, 아토믹스는 저수준 프로세서 명령어 및 OS별 특성을 활용
- CAS는 '예상되는 현재 값', '원하는 새 값', '메모리 포인터'를 전달받아 다음 2가지 일을 수행하는 아토믹 유닛
  - 예상되는 현재 값을 메모리 위치에 있는 컨텐츠와 비교
  - 두 값이 일치하면 현재 값을 원하는 새 값으로 교체
- CAS는 여러 중요한 고수준 동시성 기능을 구성하는 기본 요소
- JMM 또는 JSR에는 CAS 이야기가 나오고 있지 않음
- CAS는 구현체별 확장 기능이라고 볼 수 있음

### 3.1 Unsafe

`sun.misc.Unsafe` 클래스

- 표준 자바 플랫폼 API가 아님
- 클래스명에 걸맞게 개발자가 이 클래스를 직접 사용할 일이 거의 없음
- 어쩌다 보니 JVM 표준 로직을 무너뜨리는 용도로 거의 모든 주요 프레임워크의 구현 핵심부를 차지하게 되었음

Unsafe로 할 수 있는 일들

- 객체는 할당하지만 생성자는 실행하지 않기
- raw 메모리에 액세스하고 포인터 수준의 연산 수행
  - raw 메모리: 자료형 없이 byte 배열 단위로 취급하는 메모리 블록
- 프로세서별 하드웨어 특성 이용
  - 예시: CAS

덕분에 다음과 같은 고수준 프레임워크 기능 구현 가능

- 신속한 (역)직렬화
- thread-safe 네이티브 메모리 액세스
- 아토믹 메모리 연산
- 효율적인 객체/메모리 레이아웃
- 커스텀 메모리 펜스
  - 메모리 배리어라고도 하며, 연산의 실행 순서를 CPU나 컴파일러가 바꾸지 못하도록 강제하는 기능
- 네이티브 코드와의 신속한 상호작용
- JNI에 관한 다중 운영체제 대체물
- 배열 원소에 volatile하게 액세스

Unsafe의 입지

- 자바 SE 공식 표준이 아니지만 워낙 업계에서 활용도가 높아 사실상 표준이나 다름 없음
- 필요한 특성을 담아두는 보관 창고 용도
- 차후 변모할 가능성이 큼

### 3.2 아토믹스와 CAS

아토믹스

- 값을 증감하는 복합 연산 수행
- `get()`으로 계산 결과값을 돌려받음
- 아토믹 변수는 volatile 확장판이라고 할 수 있지만, 보다 더 유연해서 상태 의존적 업데이트를 안전하게 수행 가능
- 자신이 감싸고 있는 베이스 타입을 상속하지 않고 직접 대체하는 것도 불가
- 락-프리 하므로 데드락은 있을 수 없음
- 비교 후 업데이트 작업이 실패할 경우를 대비해 내부적인 재시도 루프 동반
  - 대개 다른 스레드가 이제 막 업데이트를 할 때 발생
  - 재시도가 많은 경우 성능이 떨어짐
  - 그러므로 경합 수준을 잘 모니터링해야 함

### 3.3 락과 스핀락

스핀락

- 블로킹된 스레드를 CPU에 활성 상태로 놔두고 아무 일도 시키지 않은 채 락을 손에 넣을 때까지 계속 재시도하게 만드는 방식
- 완전히 상호 베타적인 락보다는 가볍게 쓰자는 취지

스핀락 구현 코드는 CPU마다 다르지만 핵심 개념은 동일

- 테스트하고 세팅하는 xchg 코드는 반드시 아토믹할 것
- 스핀락에 경합이 발생하면 대기 중인 프로세서는 tight loop 실행

⇒ CAS는 예상 값이 정확한 경우 명령어로 값을 안전하게 업데이트하며, 락의 구성 요소를 형성

## 4. 동시 라이브러리 정리


### 4.1 java.util.concurrent 락

- `java.util.concurrent.locks.Lock` 인터페이스는 인트린직 락보다 더 많은 일 수행 가능

`lock()`

- 기존 방식대로 락을 획득하고 락을 사용할 수 있을 때까지 블로킹

`newCondition()`

- 락 주위 조건을 설정해 좀 더 유연하게 락 활용
- 락 내부에서 관심사 분리 가능

`tryLock()`

- 락 획득 시도
- 타임아웃 옵션 설정 가능
- 스레드가 락을 사용할 수 없는 경우에도 계속 처리 진행 가능

`unlock()`

- 락 해제

락 활용

- 여러 종류의 락 생성 가능
- 여러 메소드에 걸쳐 락을 걸어놓을 수 있음
- 한 메소드에 락을 걸고 동시에 다른 메소드는 락을 해제할 수 있음
- 논블로킹 방식으로 락을 획득하려는 스레드는 `tryLock()`으로 일단 시도해보고, 실패하면 다른 작업을 수행하거나 다시 시도

**ReentrantLock**

- Lock 주요 구현체
- 내부적으로는 int 값으로 `compareAndSwap()` 수행
- 경합이 없는 경우 락 획득 과정이 락-프리
- 락 경합이 별로 생기지 않는 시스템의 성능 향상에 유리
- 스레드가 동일한 락을 다시 획득하는 것을 재진입(reentrant) 락킹이라고 함

AbstractQueuedSynchronizer

- `compareAndSwap()`을 호출하고 Unsafe를 사용한 코드는 AbstractQueuedSynchronizer를 확장한 정적 서브클래스 Sync에 있음
- AbstractQueuedSynchronizer는 스레드 파킹 및 재개하는 메소드가 구현된 LockSupport 클래스를 사용

LockSupport

- 스레드에게 permit 발급
- 발급할 permit이 없으면 스레드는 기다려야 함
- 오직 한 가지 permit(binary semaphore)만 발급 가능
- 스레드는 permit을 받지 못한 경우 잠시 파킹되었다가 유효한 permit을 받을 수 있을 때 다시 언파킹

```java
while (!canProceed()) { ... LockSupport.park(this); }
```

`park(Object blocker)`

- 다른 스레드가 `unpark()`를 호출하거나, 스레드가 인터럽트되거나, 스퓨리어스 웨이크업이 발생될 때까지 블로킹

`parkNanos(Object blocker, long nanos)`

- `park()`와 비슷하지만, 시간 제한이 있음
- 지정 시간이 지나면 그냥 반환됨

`parkUntil(Object blocker, long deadline)`

- `parkNanos()`와 비슷하고 nanos 대신 ms 단위로 시간 제한을 받음

### 4.2 읽기/쓰기 락

- ReentrantReadWriteLock 클래스의 ReadLock과 WriteLock을 사용하여 여러 스레드가 읽기 작업을 하는 도중 다른 읽기 스레드를 블로킹하지 않게 할 수 있음
- 블로킹은 쓰기 작업 때만 발생
- 읽기 스레드가 매우 많을 경우에 적용하면 스레드 처리율이 크게 향상되고 락킹이 줄어듦

```java
public class AgeCache {
  private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
  private final Lock readLock = lock.readLock();
  private final Lock writeLock = lock.writeLock();

  public Integer getAge(String name) {
    readLock.lock();
    try {
      return cache.get(name);
    } finally {
      readLock.unlock();
    }
  }

  public void setAge(String name, Integer age) {
    writeLock.lock();
    try {
      cache.put(name, age);
    } finally {
      writeLock.unlock();
    }
  }
}
```

### 4.3 세마포어

- 세마포어는 풀 스레드나 DB 접속 객체 등 여러 리소스의 액세스를 허용하는 독특한 기술 제공
- '최대 O개 객체까지만 액세스를 허용한다'는 전제하에 정해진 수량의 permit으로 액세스 제어

```java
private Semaphore poolPermits = new Semaphore(2, true);
```

`acquire()`

- 사용 가능한 permit 수를 하나씩 줄임
- 더 이상 쓸 수 있는 permit이 없는 경우 블로킹

`release()`

- permit을 반납하고 대기 중인 스레드 중 하나에게 해제한 permit 전달

공정모드 초기화

- 리소스가 블로킹되거나 리소스를 기다리는 큐가 형성될 가능성이 커서 스레드 고갈을 막기 위해 처음부터 공정모드로 초기화하는 경우가 많음

permit이 하나뿐인 세마포어

- mutex와 동등
- 뮤텍스는 뮤텍스가 걸린 스레드만 해제할 수 있지만, 세마포어는 비소유 스레드도 해제 가능
- 데드락을 강제로 해결할 수 있음

강점

- 여러 permit을 획득/해제할 수 있는 능력
- permit을 여러 개 쓸 경우, 불공정 모드는 스레드 고갈 가능성이 크므로 공정모드가 필수

### 4.4 동시 컬렉션

ConcurrentHashMap

- 버킷 또는 세그먼트로 분할된 구조를 최대한 활용해 실질적인 성능 개선 효과를 얻음
- 각 세그먼트는 자체 락킹 정책으로 자신만의 락 세트를 가질 수 있음
- 여러 읽기 스레드가 맵을 읽는 동안, 쓰기가 필요한 경우 한 세그먼트만 락을 거는 행위 가능

copy-on-write

- iterator 및 split-iterator는 일종의 스냅샷으로 획득하기 때문에 ConcurrentModificationException 예외가 발생하지 않음
- CopyOnWriteArrayList, CopyOnWriteArraySet은 자료 구조 변경 시 배킹 배열 사본을 하나 더 생성하므로 ConcurrentModificationException 예외가 발생하지 않음
- copy-on-write 방식은 자료구조를 변경하는 횟수보다 읽는 횟수가 월등히 많은 시스템에서 유리

### 4.5 래치와 배리어

- 둘 모두 스레드 세트의 실행을 제어하는 유용한 기법
- 파이프라인 단계마다 하나의 배리어/래치를 적용하는 것이 일반적인 베스트 프랙티스

래치

- 모든 스레드가 태스크#1 → 태스크#2 → 태스크#3 순으로 실행되어야 하는 경우에 유용
- 래치는 한번만 사용 가능하며, 리셋이라는 개념이 없음
- 래치는 애플리케이션 최초 실행이나 멀티스레드 테스트 도중, 캐시 적재 등의 작업을 할 때 유용

## 5. 실행자와 태스크 추상화

- 일반적인 경우 프로그래머가 직접 저수준 스레드 문제를 직접 해결하기 보다는 `java.util.concurrent` 패키지에서 적절한 수준으로 추상화된 기능을 골라 사용하는 것이 좋음
- 스레딩 문제가 거의 없는 추상화 수준은 **concurrent task**로 현재 실행 컨텍스트 내 동시 실행 작업 단위 기술 가능
  - 일의 단위를 태스크로 바라보면 동시 프로그래밍을 단순화할 수 있음
  - 태스크를 실행하는 실제 스레드의 생명주기를 개발자가 일일이 신경 쓸 필요가 없기 때문

### 5.1 비동기 실행이란?

- 자바에서 태스크를 추상화하는 방법: 값을 반환하는 태스크를 Callable 인터페이스로 나타내는 것
- `Callable<V>`은 `call()` 메소드 하나밖에 없는 제네릭 인터페이스
  - `call()` 메소드는 V형 값을 반환하되 결과값을 계산할 수 없으면 예외를 던짐
  - Runnable과 비슷하지만 Runnable은 결과를 반환하거나 예외를 던지지 않음

스레드가 살아 있는 동안 예외 처리하기

- 프로그래밍 세계의 난제 중 하나
- 정확히 관리하지 않으면 자바 프로그램이 엉뚱한 상태에 빠져버릴 수 있음
- Runnable의 결과를 가져오는 방식은 다른 스레드를 상대로 실행 반환을 조정해야 하므로 복잡도가 높음

Callable의 추상화

- ExecutorService
  - 관리되는 스레드 풀에서 태스크 실행 메커니즘을 규정하는 인터페이스
  - 풀에 담긴 스레드를 어떻게 관리하고 몇 개의 스레드를 생성할지 결정
  - `submit()` 메소드를 통해 Runnable 또는 Callable 객체를 받음
- Executors
  - 선택한 로직에 따라 서비스 및 기반 스레드 풀을 생성하는 `new*` 팩토리 메소드 시리즈 제공
  - 보통 이 팩토리 메소드로 실행자 메소드 생성

`newFixedThreadPool(int nThreads)`

- 크기가 고정된 스레드 풀을 지는 ExecutorService 생성
- 풀 안의 스레드는 재사용되면서 여러 태스크 실행
- 태스크마다 스레드를 여러 번 생성하는 비용 절감
- 스레드가 전부 사용 중인 경우 새 태스크는 일단 큐에 보관

`newCachedThreadPool()`

- 필요한 만큼 스레드를 생성하되 가급적 재사용하는 ExecutorService 생성
- 생성된 스레드는 60초 간 유지된 후 캐시에서 삭제됨
- 소규모 비동기 태스크의 성능 향상

`newSingleThreadExecutor()`

- 스레드 하나만 가동되는 ExecutorService 생성
- 새 태스크는 스레드를 이용할 수 있을 때까지 큐에서 대기
- 동시 실행 태스크의 개수를 제한해야 하는 경우 유용

`newScheduledThreadPool(int corePoolSize)`

- 특정 시점에 태스크를 실행하거나 주기적으로 실행하는 태스크를 지원하는 ExecutorService 생성

### 5.2 ExecutorService 선택하기

- 올바른 ExecutorService를 선택하면 비동기 프로세스를 적절히 제어할 수 있고, 풀 스레드 개수를 정확히 정하면 성능이 뚜렷이 향상될 수 있음
- 커스터마이징에 유용한 옵션은 ThreadFactory 하나뿐
  - 개발자가 직접 이름, 데몬 상태, 우선순위 등의 속성을 스레드에 설정하는 커스템 스레드 생성기 작성 가능

ExecutorService 튜닝

- 어떤 하드웨어에서 서비스가 실행 중인지, 어떤 리소스에서 경합이 벌어졌는지 파악하는데 유용
- 가장 흔히 사용되는 지표: 코어 수 대비 풀 스레드 수
  - 풀 스레드 개수를 코어 개수보다 높게 잡으면 경합 문제 발생

### 5.3 포크/조인

- 자바는 개발자가 직접 스레드를 제어/관리하지 않도록 다양한 방식으로 동시성 문제 처리
- 자바 7부터 등장한 fork/join 프레임워크는 멀티 프로세서 환경에서 효율적으로 작동하는 새로운 API 제공
- 이 프레임워크는 ForkJoinPool이라는 ExecutorService의 구현체 사용

ForkJoinPool 클래스

- 관리되는 스레드 풀 제공
- 하위 분할 태스크를 효율적으로 처리
  - 하위 분할 태스크: 표준 자바 스레드보다 가벼운 스레드와 비슷한 엔티티, 적은 수의 스레드가 많은 태스크/서브태스크를 담당할 때 유용
- work-stealing 알고리즘을 사용해 스레드가 다른 스레드의 큐에서 태스크를 가져와 실행
  - `commonPool()` 정적 메소드는 전체 시스템 풀의 레퍼런스 반환
  - 공용 풀은 지연 초기화되어 필요한 시점에 생성
- 풀 크기 = Runtime.getRuntime().availableProcessors()-1

병렬도 세팅 플래그

```sh
-Djava.util.concurrent.ForkJoinPool.common.parallelism=128
```

- 하지만 매직 플래그는 조심해서 사용하자!

## 6. 최신 자바 동시성

### 6.1 스트림과 병렬 스트림

- 자바 8의 가장 큰 변경사항 lambda와 stream
  - 함수형 프로그래밍의 혜택을 누릴 수 있게 해줌
  - 모든 컬렉션은 `stream()` 메소드를 가지고 있음
  - `stream()` 메소드는 컬렉션에서 스트림을 생성하는 구현체를 생성해주는 디폴트 메소드로, 내부에서 ReferencePipeline 생성

`parallelStream()`

- 병렬로 데이터를 작업하고 그 결과를 재조정
- 내부적으로 Spliterator를 사용해 작업을 분할하고 공용 포크/조인 풀에서 연산 수행
- 까다로운 병렬 문제를 다룰 때 편리한 기법
  - 스트림은 처음부터 불변이므로 병렬 실행 도중 상태 변경으로 생기는 문제 예방 가능
- 하지만 컬렉션이 작으면 직렬 연산이 병렬 연산보다 훨씬 빠름

### 6.2 락-프리 기법

- 블로킹이 처리율에 악영향을 미친다는 전제하에 시작하는 기법
- 블로킹의 문제점: 컨텍스트 스위칭 기회를 OS에 의지

스핀락

- 락-프리 기법의 일등공신
- CPU 코어를 계속 스피닝해서, 데이터를 받자마자 컨텍스트 교환 없이 즉시 해당 코어에서 작업 준비 완료

락-프리 기법의 대가

- CPU 사용률이 높아지면서 전력 소모량이 늘어남
- 아무것도 처리하지 않는 상태로 더 많은 전력 코어 사용

### 6.3 액터 기반 기법

- 태스크를 스레드 하나보다 더 작게 나타내려는 접근 방식
  - ForkJoinPool 클래스도 해당 접근 방식 중 하나

액터

- 그 자체로 고유한 상태와 로직을 가짐
- 다른 액터와 소통하는 메일박스 체계를 갖춘 작고 독립적인 처리 단위
- 가변적 상태는 공유하지 않고 오직 불변 메시지를 통해서만 상호 통신하면서 상태 관리
- 액터 간 통신은 비동기적이며 메시지 기반으로 정해진 일 수행
- 병렬 시스템 내부에서 하나의 네트워크를 형성하고, 각자 작업을 수행함으로써 하부 동시 모델을 완전히 추상화한 모습

Akka

- JVM 계열 언어에서 가장 유명한 액터 기반 프레임워크
- 스칼라 언어로 작성됐지만 자바 API도 제공
- 주목적: 동시 프로그래밍을 곤란하게 만드는 제반 문제들 해결
- 스레드 실패/복원을 처리하는 방법 표준화

전통적인 락킹 체계보다 아카를 쓰는 것이 더 좋은 이유들

- 도메인 모델 내에서 가변 상태를 캡슐화하는 건 의외로 까다로운 일, 객체 내부 요소를 가리키는 레퍼런스가 언제라도 제어권 밖으로 벗어날 수 있기 때문에
- 상태를 락으로 보호하면 처리율이 크게 떨어질 수 있음
- 락을 쓰면 데드락을 비롯한 여러 문제가 발생할 수 있음

액터 모델 유스케이스

- 유용하지만 다른 기법 전체를 대체하는 범용 툴은 아님
- 불변 메시지 비동기 전송, 가변 상태 공유 금지, 제한된 메시지 처리 시간 등의 특성이 잘 맞는 유스케이스에 사용할 것
- 요청-응답의 비동기 처리, 가변 상태 공유, 무제한 실행 등의 특성을 고려해야 한다면 다른 방법으로 시스템을 추상화하자
