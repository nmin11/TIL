VMSpec

- 자바 가상 머신 명세
- 표준 자바 구현체가 코드를 실행하는 방법이 기술되어 있음
  - 인터프리터로 자바 바이트코드를 실행하는 사양
- 그러나 인터프리터 해석 및 구동 환경은 대체로 기계어 직접 실행 환경보다 성능이 떨어짐

⇒ JIT 컴파일 기법으로 문제를 해결함

- 동적 컴파일 기능
- JVM이 실행 중인 메소드를 지켜보다가 직접 실행 가능한 코드로 컴파일할 메소드를 분별하는 메커니즘

9장에서는...

- 바이트코드 해석을 간략히 살펴볼 것
- 다른 인터프리터와 핫스팟의 차이점에 대해
- profile 기반의 최적화 기초 개념
- 코드 캐시 및 핫스팟 컴파일 서브시스템의 기본적인 내용

## 1. 바이트코드 해석

- JVM 인터프리터는 일종의 *stack machine* 처럼 작동하므로 계산 결과를 바로 보관하는 레지스터가 없음
  - 작업할 값은 모두 평가 스택에 놓고 스택 머신 명령어로 스택 최상단에 위치한 값을 변환하는 식으로 작동

JVM이 데이터를 담아 놓는 공간들

- 평가 스택: 메소드별로 하나씩 생성됨
- 로컬 변수: 결과 임시 저장 (특정 메소드별로 존재)
- 객체 힙: 메소드끼리, 스레드끼리 공유됨

### 1.1 JVM 바이트코드 개요

JVM 스택 머신 opcode

- 1byte로 구성
  - 그래서 이름도 바이트코드
  - 그래서 0부터 255까지 지정 가능하고, 그중 약 200개 사용 중 (Java 10)
- 단축형 명령어, 타입별 명령어들을 포함
- 개념적으로는 단순하지만 상당히 많은 옵코드가 할당되어 있음

패밀리 단위

- 바이트코드 명령어는 대부분 한쪽이 기본형, 다른 한쪽은 참조형으로 쓸 수 있게 '패밀리 단위'로 구성됨

endian

- 자바는 처음부터 이식성을 염두에 두고 설계된 언어
- 하드웨어 아키텍처 빅 엔디언, 리틀 엔디언 모두 바이트코드 변경없이 실행 가능하도록 명세에 규정되어 있음
  - JVM 바이트코드는 둘 중 어느 엔디언을 따를지 결정해야 함

❖ `c1`: 2byte 상수 풀 인덱스  
❖ `i1`: 현재 메소드의 지역 변수  
❖ `()`: opcode 패밀리 중 단축형을 지닌 opcode가 있음을 의미

**로드/스토어 카테고리**

상수 풀에서 데이터를 로드하거나 스택 상단을 힙 객체 필드에 저장하는 등의 작업

| 패밀리 | 인수 | 설명 |
| :--: | :--: | :-- |
| load | (i1) | 지역 변수 i1 값을 스택에 로드 |
| store | (i1) | 스택 상단을 지역 변수 i1에 저장 |
| ldc |  | CP#c1이 가리키는 값을 스택에 로드 |
| const |  | 단순 상수값을 스택에 로드 |
| pop |  | 스택 상단에서 값 제거 |
| dup |  | 스택 상단에 있는 값 복제 |
| getField | c1 | 스택 상단에 위치한 객체에서 CP#c1이 가리키는 필드명을 찾아 그 값을 스택에 로드 |
| putField | c1 | 스택 상단의 값을 CP#c1이 가리키는 필드에 저장 |
| getstatic | c1 | CP#c1이 가리키는 정적 필드값을 스택에 로드 |
| putstatic | c1 | 스택 상단의 값을 CP#c1이 가리키는 정적 필드에 저장 |

- ldc: 현재 클래스의 상수 풀에 있는 상수를 로드
  - String, 기본형 상수, 클래스 리터럴, 기타 상수가 해당됨
- const: 매개 변수 없이 `aconst_null` `dconst_0` `iconst_m1` 과 같은 진짜 상수만 로드

**산술 카테고리**

기본형에만 적용되고 순수하게 스택 기반으로 연산을 수행하기 때문에 인수가 없음

| 패밀리 | 설명 |
| :--: | :-- |
| add | 스택 상단의 두 값을 더함 |
| sub | 스택 상단의 두 값을 뺌 |
| div | 스택 상단의 두 값을 나눔 |
| mul | 스택 상단의 두 값을 곱 |
| (cast) | 스택 상단의 값을 캐스팅 |
| neg | 스택 상단의 값을 부정 |
| rem | 스택 상단의 두 값을 나눈 나머지 |

**흐름 제어 카테고리**

소스 코드의 순회, 분기문을 바이트코드 수준으로 표현  
for, if, while, switch 제어문을 컴파일하면 아래와 같은 바이트코드로 변환됨

| 패밀리 | 인수 | 설명 |
| :--: | :--: | :-- |
| if | (i1) | true인 경우 인수의 위치로 분기 |
| goto | i1 | 주어진 오프셋으로 무조건 분기 |
| tableswitch |  |  |
| lookupswitch |  |  |

- if 옵코드 패밀리에 속한 opcode가 상당히 많이 있음
- jsr, ret는 자바 6부터 deprecated 됨

**메소드 호출 카테고리**

자바 프로그램에서 새 메소드로 제어권을 넘기는 유일한 장치  
자바 플랫폼은 지역 흐름 제어와 다른 메소드로 제어권을 넘기는 행위를 분명히 구분함

| opcode | 인수 | 설명 |
| :--: | :--: | :-- |
| invokevirtual | c1 | CP#c1이 가리키는 메소드를 가상 디스패치를 통해 호출 |
| invokespecial | c1 | CP#c1이 가리키는 메소드를 특별한 디스패치를 통해 정확하게 호출 |
| invokeinterface | c1, count, 0 | CP#c1이 가리키는 인터페이스 메소드를 인터페이스 오프셋 룩업을 통해 호출 |
| invokestatic | c1 | CP#c1이 가리키는 정적 메소드를 호출 |
| invokedynamic | c1, 0, 0 | 호출해서 실행할 메소드를 동적으로 탐색 |

- JVM 바이트코드의 전문 용어들
  - call site: caller 메소드 내부에서 callee 메소드를 호출하는 지점
  - nonstatic 메소드 호출은 어느 객체의 메소드인지 반드시 해석해야 함
    - receiver object: 찾아낸 객체
    - receiver type: 찾아낸 객체의 런타임 타입
    - 정적 메소드 호출은 항상 invokestatic을 사용하므로 receiver object가 없음
- invokevirtual: 인스턴스 메소드 호출
- invokeinterface: 자바 인터페이스에 선언된 메소드 호출
- invokespecial: private 메소드, 생성자 호출
- invokedyamic: non-java 동적 언어를 지원하고자 추가된 기술

**플랫폼 카테고리**

객체별로 힙 저장 공간을 새로 할당하거나, 고유 락을 다룸

| opcode | 인수 | 설명 |
| :--: | :--: | :-- |
| new | c1 | CP#c1이 가리키는 타입의 객체에 공간 할당 |
| newarray | prim | 기본형 배열에 공간 할당 |
| anewarray | c1 | CP#c1이 가리키는 타입의 객체 배열에 공간 할당 |
| arraylength |  | 스택 상단에 위치한 객체를 그 길이로 치환 |
| monitorenter |  | 스택 상단의 객체 모니터 잠금 |
| monitorexit |  | 스택 상단의 객체 모니터 잠금 해제 |

---

바이트코드와 세이프포인트

- JVM 애플리케이션 스레드 하나하나는 실제 OS 스레드
- 바이트코드 사이사이는 애플리케이션 스레드를 멈추기에 이상적이고 단순한 세이프포인트

### 1.2 단순 인터프리터

- 가장 단순한 인터프리터는 switch 문이 포함된 while 루프 형태
- [Ocelot 프로젝트](https://github.com/kittylyst/ocelotvm)는 단순 인터프리터를 구현한 교육용 프로젝트

### 1.3 핫스팟에 특정한 내용

- 핫스팟은 template interpreter라서 시작할 때마다 동적으로 인터프리터를 구축
- 그러므로 처음 접하는 사람들에겐 인터프리터 소스 코드조차 분석하기 어려움
- 게다가 핫스팟은 네이티브 플랫폼의 스택 플랫폼 레이아웃과 함께 최대의 성능을 내기 위해 상당히 많은 assembly 코드를 사용함
- 게다가 VMSpec에 없는 핫스팟 전용 바이트코드까지 있음

## 2. AOT와 JIT 컴파일

### 2.1 AOT 컴파일

- AOT 컴파일: 프로그램 소스 코드를 컴파일러에 넣고 바로 실행 가능한 기계어를 뽑아내는 과정
- AOT 컴파일의 최적화 기회는 단 한번뿐
- 목표: 프로그램을 실행할 플랫폼과 프로세서 아키텍처에 딱 맞는 실행 코드를 얻는 것
  - 대상이 고정되어 프로세서별로 특수한 기능을 활용해 프로그램 속도를 높일 수 있음
- 하지만 대부분의 환경에서는 어떤 플랫폼에서 실행될지 모르는 상태에서 생성되므로 보수적인 선택을 해야 함
- 결국 AOT 컴파일 바이너리는 CPU 기능을 최대한 활용하지 못하는 경우가 많고 항상 성능 향상의 숙제가 남게 됨

### 2.2 JIT 컴파일

- JIT 컴파일: 런타임에 프로그램을 고도로 최적화한 기계어로 변환하는 기법
- 핫스팟을 포함한 대부분의 주요 JVM은 JIT 컴파일러를 사용함
- 런타임 실행 정보를 수집해서 어느 부분이 자주 쓰이고, 어느 부분을 최적화해야 가장 효과가 좋은지 profile을 만들어 결정을 내림
- 이러한 기법을 **PGO(profile-guided optimization)** 라고 부름

PGO

- profiling 및 최적화 비용 vs 성능 향상 기대치 사이에서의 균형이 중요
- 런타임에 바이트코드를 네이티브 코드로 컴파일
  - CPU, 메모리 등 공통 리소스를 활용해야 하므로 JIT 컴파일은 산발적으로 수행
- VM은 최적화하기 좋은 포인트를 찾기 위해 각종 프로그램 관련 지표를 수집
  - profiling 서브시스템은 현재 어떤 메소드가 실행 중인지 항시 추적
  - 컴파일 적정 한계치를 넘어선 메소드가 발견되면 emitters 서브시스템이 컴파일 스레드를 가동해 바이트코드를 기계어로 변환

### 2.3 AOT 컴파일 vs JIT 컴파일

AOT 컴파일

- 소스 코드에서 바로 기계어가 생성되고 컴파일 단위별로 대응되는 기계어를 어셈블리로 바로 사용 가능
  - 그러므로 코드 성능 특성이 그리 복잡하지 않음
- 하지만 최적화 결정을 내리는데 유용한 런타임 정보를 활용할 수 없음
  - LTO(link-time optimization) 같은 기법이 있지만 핫스팟에 비하면 아직 초기 개발 단계
- 특정 프로세서에 타게팅된 환경이라면 모든 프로세서 최적화 기법을 총동원할 수 있음
- 다만 확장성이 낮아서 다양한 아키텍처에서 최대 성능을 내기 어려움

JIT 컴파일

- 릴리즈를 할 때마다 새로운 프로세서 기능 관련 최적화 코드를 추가할 수 있음
- 재컴파일 없이도 신기능을 활용할 수 있음

⇒ AOT 컴파일 환경도 초기 단계이지만 꾸준히 발전하고 있음

## 3. 핫스팟 JIT 기초

- 핫스팟의 기본 컴파일 단위는 전체 메소드
  - 한 메소드의 바이트코드가 한꺼번에 네이티브 코드로 컴파일됨
- 핫스팟은 핫 루프를 OSR(On Stack Replacement) 기법으로 컴파일하는 기능도 제공
  - 어떤 메소드가 컴파일할 만큼 자주 호출되지 않지만 적합한 루프가 포함돼 있고 루프 바디 자체가 메소드인 경우에 사용

### 3.1 klass 워드, vtable, 포인터 스위즐링

- 핫스팟은 멀티스레드 C++ 애플리케이션
- OS 관점에서 모든 자바 프로그램은 한 멀티스레드 애플리케이션의 일부
- JIT 컴파일 서브시스템을 구성하는 스레드는 핫스팟 내부에서 가장 중요한 스레드들
  - profiling 스레드와 컴파일러 스레드도 여기에 포함됨

(이미지 첨부 - jit-compiler.png)

- 최적화된 기계어 생성 후 해당 klass의 vtable은 새로 컴파일된 코드를 가리키도록 수정됨
  - vtable 포인터 업데이트 작업을 **pointer swizzling** 이라고 부름

### 3.2 JIT 컴파일 로깅

```bash
java -XX:+PrintCompilation
```

- 컴파일 이벤트 로그가 표준 출력 스트림에 출력됨
- 출력문 분석
  - 컴파일 시간 (VM 시작 후 ms)
  - 컴파일된 메소드의 순번
  - n: 네이티브 메소드
  - s: 동기화 메소드
  - !: 예외 핸들러를 지닌 메소드
  - %: OSR을 통해 컴파일된 메소드

```bash
java -XX:+LogCompilation -XX:+UnlockDiagnosticVMOptions
```

- LogCompilation 이 진단용 옵션이기 때문에 Unlock 옵션도 부가적으로 필요
- VM이 바이트코드를 네이티브 코드로 어떻게 최적화했는지 등을 XML 태그 형태의 로그파일로 출력
- 표준 포맷이 없기 때문에 적절히 해석하는 방법을 배우거나 툴링이 필요

### 3.3 핫스팟 내부의 컴파일러

- 핫스팟 JVM에는 C1, C2라는 두 JIT 컴파일러가 있음
- C1: GUI 애플리케이션 및 기타 클라이언트 프로그램
- C2: 실행 시간이 긴 서버 애플리케이션
- 요즘에는 구분 기준이 뚜렷하지 않고 새로운 환경에 맞게 최대한 성능을 발휘하도록 변화했음
- C1, C2 모두 메소드 호출 횟수에 따라 컴파일 트리거링
  - 호출 횟수가 특정 한계치에 이르면 VM이 알림을 받고 해당 메소드를 컴파일 큐에 넣음
- 컴파일 프로세스는 먼저 메소드의 내부 표현형을 생성하고, 인터프리티드 단계에서 수집한 profiling 정보를 바탕으로 최적화 로직 적용
- C1은 컴파일 시간을 최소화하고, C2는 최적화를 최대화하는 방향으로 설계됨
- SSA(single static assignment)
  - 변수를 일체 재할당하지 않는 코드로 변환
  - C1, C2 모두 사용하는 공통 기법
  - 자바식으로 보면 오직 final 변수만 쓰도록 바꾸는 셈

### 3.4 핫스팟의 단계별 컴파일

*tiered compilation*

- 인터프리티드 모드 → C1 컴파일 모드 → C2 컴파일 모드
- 더 세부적으로 보면...
  - 레벨 0: 인터프리터
  - 레벨 1: C1 - 풀 최적화 (profiling x)
  - 레벨 2: C1 - invocation counter + backedge counter
  - 레벨 3: C1 - full profiling
  - 레벨 4: C2
- 모든 레벨을 다 거치는 것이 아니라, 컴파일 방식마다 경로가 다름

| 경로 | 설명 |
| :--: | :-- |
| 0-3-4 | 인터프리터, C1-full profiling, C2 |
| 0-2-3-4 | 인터프리터, C1 full compile, C2 |
| 0-3-1 | 단순 메소드 |
| 0-4 | C2 직행 |

- 단계별 컴파일은 오래전부터 디폴트였기 때문에 성능을 튜닝할 일이 거의 없음
- 컴파일드 메소드 작동 로직이 복잡해지기 쉬우므로 작동 원리 정도는 알아두는 것이 좋음

## 4. 코드 캐시

- JIT 컴파일드 코드는 **코드 캐시** 라는 메모리 영역에 저장됨
- 코드 캐시에는 인터프리터 부속 등 VM 자체 네이티브 코드가 함께 들어 있음
- 코드 캐시는 최대 크기가 고정되어 있고 확장이 불가능
  - 코드 캐시가 꽉 차면 JIT 컴파일이 더이상 되지 않고, 인터프리터로만 실행됨
- 코드 캐시는 미할당 영역과 프리 블록 연결 리스트를 담은 힙으로 구현됨
  - 네이티브 코드가 제거될 때마다 해당 블록이 프리 리스트에 추가됨
  - 블록 재활용은 sweeper 프로세스가 담당
- 네이티브 메소드가 새로 저장되면 컴파일드 코드를 담기에 충분한 크기의 블록을 프리 리스트에서 찾아봄
  - 만약 없다면 여유 미할당 공간에 새 블록 생성
- 네이티브 코드가 캐시에서 제거되는 경우
  - 추측성 최적화 적용 결과 틀린 것으로 판명되어 역최적화될 때
  - 단계별 컴파일 중 다른 컴파일 버전으로 교체되었을 때
  - 메소드를 지는 클래스가 언로딩되었을 때

❖ 코드 캐시 최대 크기 조정 플래그

```bash
java -XX:ReservedCodeCacheSize=<n>
```

- 단계별 컴파일 기능을 켜면 C1 클라이언트 컴파일러의 낮아진 컴파일 한계치에 도달하는 메소드가 늘어남
- 이를 감안해 디폴트 최대 크기값은 늘어난 컴파일드 메소드를 수용할 수 있게 더 커짐

### 4.1 단편화

- 컴파일드 코드가 C1 → C2 로 치환된 후 삭제가 많아지면 코드 캐시가 단편화됨
- 결국 미할당 영역이 모두 소진되고 여유 공간은 전부 프리 리스트에 있는 것으로 표시될 것
- 그러면 새로 컴파일된 네이티브 코드를 담을 큰 블록을 찾기 위해 할당기는 연결 리스트를 샅샅이 뒤져야 할 것
  - 스위퍼 역시 재활용 가능 블록을 찾기 위해 바빠짐
- 메모리 블록을 재배치하는 압착 과정이 필요해짐

## 5. 간단한 JIT 튜닝법

"컴파일을 원하는 메소드에게 아낌없이 리소스를 베풀라"

먼저 점검해야 할 포인트

1. `PrintCompilation` 옵션을 사용해 컴파일 이벤트를 확인
2. 어떤 메소드가 컴파일되는지 기록된 로그 수집
3. `ReservedCodeCacheSize` 옵션을 사용해 코드 캐시 늘리기
4. 애플리케이션 재실행
5. 확장된 캐시에서 컴파일드 메소드 확인

JIT 컴파일에 내재된 불확정성을 고려해서 2가지 사실을 관찰해야 함

- 캐시 크기를 늘리면 컴파일드 메소드 규모가 유의미한 방향으로 커지는가?
- 주요 트랜잭션 경로상에 위치한 주요 메소드가 모두 컴파일되고 있는가?

확인해야 할 것들

- 코드 캐시 공간이 모자라서 JIT 컴파일이 끊기지는 않는지
- 캐시 크기를 늘려도 컴파일드 메소드 개수가 그대로인지
- 트랜잭션이 몰리는 메소드가 컴파일 로그에 전부 나타나고 있는지

⇒ 간단한 JIT 튜닝 방법만 알아도 애플리케이션의 성능을 엄청나게 끌어올릴 수 있다.
