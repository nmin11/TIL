_스스로 움직이는 사용자 에이전트_

- 웹 로봇은 사람과의 상호작용 없이 연속된 웹 트랜잭션들을 자동으로 수행하는 소프트웨어 프로그램
- 웹 사이트들을 떠돌아다니면서 컨텐츠를 가져오고 하이퍼링크를 따라가고 발견한 데이터를 처리함
- '크롤러', '스파이더', '웜', '봇' 등 각양각색의 이름으로 불림

※ 예시

- 주식시장 서버에 매 분 GET 요청을 보내서 얻은 데이터로 주가 추이 그래프를 생성하는 주식 그래프 로봇
- WWW의 규모와 진화에 대한 통계 정보를 수집하는 웹 통계 조사 로봇
  - 웹 페이지 개수를 세고 각 페이지의 크기, 언어, 미디어 타입을 기록함
  - http://www.netcraft.com → 웹 사이트들이 어떤 서버를 사용하고 있는지 통계 자료를 수집함
- 검색 데이터베이스를 만들기 위해 발견한 모든 문서를 수집하는 검색엔진 로봇
- 상품 가격 데이터베이스를 만들기 위해 온라인 쇼핑몰의 카탈로그에서 웹 페이지를 수집하는 가격 비교 로봇

<br>

## 1. 크롤러와 크롤링

- 웹 페이지를 가져온 뒤, 그 페이지가 가리키는 모든 웹 페이지를 가져오고, 또 그 페이지의 페이지들을 가져오는,<br>웹을 재귀적으로 반복 순회하는 로봇
- 크롤러 혹은 스파이더라고 불림
  - HTML 하이퍼링크들로 만들어진 웹을 따라 '기어다니기' 때문
- 인터넷 검색엔진은 웹을 돌아다니며 만나는 모든 문서를 끌어오기 위해 크롤러를 사용함
  - 문서들은 나중에 처리되어 검색 가능한 데이터베이스로 만들어짐
  - 검색 DB는 특정 단어를 포함한 문서를 찾을 수 있게 해줌
  - 찾아서 가져와야 하는 페이지들이 수십억 개에 이르다 보니 필연적으로 가장 복잡한 로봇들 중 하나가 되었음

### 1.1 어디서 시작하는가: '루트 집합'

- 굶주린 크롤러를 풀어놓기 전에 출발지점이 주어져야 함

(이미지 첨부 - 크롤러 루트 집합)

- 크롤러가 방문을 시작하는 URL들의 초기 집합을 **root set**이라고 부름
- 루트 집합을 고를 땐 관심 있는 웹 페이지들을 충분히 크롤링하기 위해 충분히 다른 장소의 URL들을 선택해야 함
- 일반적으로 웹 대부분을 커버하기 위해 루트 집합에 너무 많은 페이지가 있을 필요는 없음
- 좋은 루트 집합은 크고 인기 있는 웹 사이트, 새로 생성된 페이지 목록,<br>자주 링크되지만 잘 알려져 있지 않은 페이지 목록으로 구성되어 있음
- 대규모 크롤러 제품들은 사용자들이 루트 집합에 새로운 페이지나 잘 알려지지 않은 페이지들을 추가하는 기능을 제공함
- 루트 집합은 시간이 지남에 따라 성장하며 새로운 크롤링을 위한 시드 목록이 됨
