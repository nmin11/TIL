- 트래픽이 급증하거나, 동영상 인코딩 같은 무거운 작업을 하거나, 예측이 어려운 경우 애플리케이션을 **decouple**해야 함
- 분리 계층의 확장
  - SQS: queue model
  - SNS: pub/sub model
  - Kinesis: real-time streaming model
- 이 서비스들은 독립적으로 서비스를 확장할 수 있음

<br>

## Amazon SQS

### What's a queue?

- SQS Queue는 메시지를 포함
- 메시지를 담기 위해서 SQS Queue에 메시지를 전송하는 주체가 **Producer**
  - 여러 생산자가 여러 메시지를 SQS Queue로 보내도록 할 수 있음
- 메시지는 무엇이든 상관없음
- Queue에서 메시지를 처리하고 수신해야 하는 대상이 **Consumer**
  - 소비자는 Queue로부터 메시지를 폴링
  - 메시지를 처리하고, Queue에서 해당 메시지 삭제
- Queueing 서비스는 생산자와 소비자를 분리하는 buffer 역할 수행

### Standard Queue

- AWS의 가장 오래된 서비스 (10년이 넘어감)
- fully managed service, used to decouple applications
- 특성
  - 무제한 처리량을 얻을 수 있음!
    - 초당 원하는 만큼 메시지를 보낼 수 있고 queue에도 원하는 만큼 메시지를 포함시킬 수 있음
  - 각 메시지는 기본 4일에서 최대 14일까지 유지 가능
  - low latency
    - 메시지를 보내거나 받을 때 10ms 내에 응답을 받을 수 있음
  - 각 메시지는 256KB 미만이어야 함
- 중복된 메시지가 있을 수 있음 (at least once delivery)
- out of order 메시지가 있을 수 있음 (best effor ordering)

### Producing Messages

- 생산자는 SDK SendMessage API를 호출해서 SQS를 사용할 것
- 소비자가 해당 메시지를 읽고 삭제할 때까지 SQS에 유지됨
- 메시지 유지 기간: 4일 ~ 14일

### Consuming Messages

- 소비자에 해당할 수 있는 것들: EC2 인스턴스, 서버들, AWS Lambda 등
- 소비자는 SQS 메시지를 폴링 (한 번에 최대 10개까지 받을 수 있음)
- 메시지 처리
  - ex) 메시지 내용을 RDS DB에 저장
- DeleteMessage API를 호출해서 메시지 삭제

### Multiple EC2 Instances Consumers

- 메시지를 수신하고 처리할 소비자를 여럿 가질 수 있음
- ex) SQS 메시지 처리를 위해 3개의 EC2 인스턴스를 두는 경우
- 만일 메시지가 소비자에 의해 충분히 빠르게 처리되지 않으면 다른 소비자가 수신
  - 그렇기 때문에 **at least once delivery**라고 하는 것!
  - 또한 이 때문에 **best-effort message ordering**을 수행하는 것
- 소비자가 메시지 처리 이후 삭제를 해줘야 다른 소비자가 같은 메시지를 보지 않게 할 수 있음
- 소비자를 추가하는 수평 확장을 통해 처리량 개선
  - ASG가 수평 확장을 할 수 있도록 SQS의 ApproximateNumberOfMessages 지표를 활용할 수 있을 것

### Security

- **Encryption**
  - HTTPS API를 활용한 in-flight 암호화
  - KMS 키를 사용하여 at-rest 암호화
  - 원한다면 client-side 암호화도 가능 (SQS 기본 지원은 아님)
- **Access Controls**
  - SQS API 액세스 제어를 위한 IAM policy
- **SQS Access Policies**
  - S3 bucket policy와 유사
  - SQS Queue에 대한 cross-account access를 수행해야 할 때
  - SNS, S3 등 다른 서비스에서 SQS Queue write 권한을 줄 때

### Queue Access Policy

좋은 활용 사례 2가지가 있음

**Cross Account Access**

- 어떤 account의 SQS Queue에 다른 account가 접근해야 하는 경우
- 교차 계정 access를 위한 Queue Access Policy 생성
- 생성된 policy를 SQS Queue에 첨부해야 함

**Public S3 Event Notifications To SQS Queue**

- S3 버켓에 객체를 업로드하면 SQS Queue에 자동으로 메시지를 보내는 방식
- SQS Queue는 S3 버켓에 메시지를 작성할 수 있는 권한을 부여해야 함

### Message Visibility Timeout

- 소비자가 메시지를 폴링하면, 해당 메시지는 다른 소비자들에게 **invisible**
- 기본값으로, "message visibility timeout"은 **30초**
  - 그 말은 즉, 30초 내에 메시지가 처리되어야 한다는 뜻!
- timeout 시간 내에 다른 ReceiveMessage 요청이 들어와도 메시지는 반환되지 않음
- 하지만 만약 message visibility timeout이 끝나고도 메시지가 삭제되지 않았다면 메시지는 다시 "visible"
- 그러므로 메시지는 한 번 처리되지 못했으면 **twice**로 처리될 수 있는 것
- 이 시간을 좀 더 벌기 위해 **ChangeMessageVisibility** API를 호출할 수 있음
- visibility timeout이 길면 re-processing이 오래 걸리고, 짧으면 중복 메시지를 받게 될 수 있는 것
- 그러므로 timeout 값을 애플리케이션에 합당한 값으로 설정하는 게 중요
  - 또한 소비자가 시간이 좀 더 필요하다는 것을 알 때 ChangeMessageVisibility API를 호출하도록 해야 함

### Dead Letter Queue

- message visibility timeout 이후에도 삭제되지 않는 메시지들이 많을 경우를 위해 threshold를 설정해야 함
- **MaximumReceives** threshold를 초과하면 메시지는 DLQ로 가게 됨
- DLQ는 디버깅을 위해 존재
- DLQ 또한 Queue이므로, 만료되기 전에 처리되어야 함
  - DLQ에서의 유지 기간을 14일 정도로 잡는 것이 좋음

### Delay Queue

- 소비자들이 메시지를 즉각적으로 보지 못하도록 하는 것
- 기본값은 0초이며, 최대 15분까지 지연 가능
- queue 레벨에서 기본값을 지정하거나, 메시지를 보낼 때마다 **DelaySeconds** parameter로 지연 시간을 설정할 수도 있음

### Long Polling

- 소비자가 queue 메시지를 요청할 때, queue가 비어있으면 메시지가 도착할 때까지 "wait"할 수 있음
- Long Polling은 SQS queue로 보내는 API 호출 횟수를 줄일 수 있음
- queue가 메시지를 수신함과 동시에 소비자도 알 수 있게 되므로 latency도 줄어듦
- 1초에서 20초까지 지정 가능 (20초가 선호됨)
- queue level에서 활성화 or **WaitTimeSeconds** API level 사용

### SQS Extended Client

- 최대 메시지 크기 제한 256KB을 넘어, 1GB의 대용량 메시지를 보내고 싶다면?
- SQS Extended Client라는 이름의 Java Library 사용
- Flow
  - 생산자는 대용량 메시지를 S3 버켓으로 전송
  - SQS queue로는 S3 버켓의 metadata 메시지 전송
  - 소비자는 SQS Extended Client를 활용해서 queue로부터 메시지를 읽는 시점에 S3 버켓에서 데이터를 받아옴
- 비디오 파일에 대한 작업을 할 때 유용

### Must know API

- CreateQueue(MessageRetentionPeriod), DeleteQueue
- PurgeQueue: queue 안의 모든 메시지 삭제
- SendMessage(DelaySeconds), ReceiveMessage, DeleteMessage
- MaxNumberOfMessage: default 1, max 10 (for ReceiveMessage API)
- ReceiveMessageWaitTimeSeconds: Long Polling
- ChangeMessageVisibility: 메시지 timeout
- Batch APIs: SendMessage, DeleteMessage, ChangeMessageVisibility
  - API 호출 횟수를 줄여서 비용 절감

### FIFO Queue

- queue 안의 메시지들이 순서대로 처리됨
- limited throughput: 배치 없이 초당 300개 메시지 / 배치로는 초당 3000개 메시지
- 중복을 제거해서 정확하게 한 번 메시지를 보내게끔 할 수 있음
- 개발자 또한 메시지가 소비자의 의해 순서대로 처리된다는 것을 알 수 있음

#### FIFO - Deduplication

- 중복제거 간격은 5분
- 5분 이내에 동일한 메시지를 보내면 해당 메시지는 삭제되는 것
- 2 de-duplication methods
  - content-based deduplication: SHA-256 해시로 메시지 본문을 비교
  - 메시지 전송 시 Message Deduplication ID 직접 명시

#### FIFO Message Grouping

- FIFO queue로 메시지를 보낼 때 **MessageGroupID**를 동일한 값으로 적용하면 해당 그룹은 한 명의 소비자만을 가짐
  - 해당 그룹은 그 한 명의 소비자를 위해 메시지가 순서대로 처리됨
- 메시지의 subset 레벨에서 메시지를 순서대로 처리하고자 한다면, 이 때는 MessageGroupID를 다르게 줘야만 함
  - 동일한 MessageGroupID를 갖는 메시지들은 해당 그룹 내에서 순서대로 처리
  - 각 Group ID는 서로 다른 소비자를 가리킴 (메시지들을 병렬적으로 처리 가능)
  - 여러 그룹에 걸쳐 순서를 지키는 것은 보장되지 않음

<br>

## Amazon SNS

- 메시지 하나를 여러 수신자에게 전송해야 한다면?
- 수신 서비스가 하나씩 늘 때마다 direct integration을 하는 것은 번거로움
- 그 대신 Pub / Sub을 활용하자!
  - 서비스는 SNS topic으로 메시지 전송
  - 해당 topic에는 여러 subscriber가 있고, 이들은 해당 topic의 메시지들을 수신하게 됨
- "event producer"는 오직 하나의 SNS topic으로만 메시지 전송
- "event receivers"는 해당 topic과 관련된 알림을 받으려는 subscribers
- 각 subscriber는 해당 topic의 모든 메시지를 받게 됨 (메시지를 필터링하려는 경우에도 받을 수 있음)
- 한 topic 당 12,500,000 이상의 subscriptions 가능
- 한 account 당 100,000개의 topic을 가질 수 있음
- SNS를 활용해서 할 수 있는 것들
  - 이메일 전송
  - SMS 전송
  - HTTP(S) 엔드포인트로 데이터 전송
  - SQS queue에 매시지 직접 전송
  - Lambda 함수가 코드를 실행하도록 지시
  - Kinesis Data Firehose를 통해 데이터를 S3나 Redshift로 전송

### SNS integrates with a lot of AWS services

- SNS는 다양한 AWS 서비스들로부터 데이터를 수신받기도 함
- it can be...
  - CloudWatch Alarms
  - Auto Scaling Group (Notifications)
  - CloudFormation (Stack Changes)
  - AWS Budgets
  - S3 Bucket (Events)
  - AWS DMS (New Replic)
  - Lambda
  - DynamoDB
  - RDS Events
  - and so on

### How to publish

- SDK를 활용한 Topic Publish
  - Create a topic
  - Create a subscription (or many)
  - Publish to the topic
- 모바일 앱 SDK 전용 Direct Publish
  - Create a platform application
  - Create a platform endpoint
  - Publish to the platform endpoint
  - Google GCM, Apple APNS, Amazon ADM과 함께 작동

### Security

- **Encryption**
  - HTTPS API를 활용한 in-flight 암호화
  - KMS 키를 사용하여 at-rest 암호화
  - 원한다면 client-side 암호화도 가능 (암호화 및 해독은 클라이언트의 몫)
- **Access Controls**
  - SNS API 액세스 제어를 위한 IAM policy
- **SNS Access Policies**
  - S3 bucket policy와 유사
  - SNS Topics에 대한 cross-account access를 수행해야 할 때
  - S3와 같은 다른 이벤트가 SNS topic을 작성할 수 있도록 할 때

### SQS + SNS: Fan Out

- 여러 SQS queue에 메시지를 전송할 때 모든 queue에 개별적으로 메시지를 보내면 문제가 발생할 수 있음
  - 애플리케이션의 비정상 종료
  - 전송 실패
  - 나중에 SQS queue를 추가할 때에 대한 번거로움
- Idea of Fan Out: SNS Topic에 한 번 push하면, 여러 개의 SQS Queue가 subsciber로써 메시지를 받는 구조
  - 각 queue들은 subscriber가 되며, 이들 모두 SNS에 전송된 메시지를 받게 됨
- 완전히 분리된 모델이므로, 데이터 손실이 발생하지 않음
- SQS allow for :
  - data persistence
  - 지연 처리
  - 작업 재시도
- 이를 활성화하기 위해 SQS queue access policy는 SNS가 queue에 대한 쓰기 권한을 가질 수 있도록 해야 함
- SQS FIFO만 구독하게 함으로서 SNS FIFO를 구성할 수 있음
  - 이 경우 SNS topic 이름이 `.fifo`로 끝나게 해야 함

### Message Filtering

- SNS topic's subscriptions에게 전송할 메시지를 필터링하는 JSON policy
- 만약 subscription에 filter policy가 없다면 모든 메시지를 받게 될 것

<br>

## Kinesis

### Overview

- 스트리밍 데이터를 실시간으로 **수집**, **처리**, **분석**할 수 있게 도와줌
- ingest real-time data such as :
  - Application logs
  - Metrics
  - Website clickstreams
  - IoT telemetry data
- Kinesis를 구성하는 4개의 하위 서비스가 있음
  - **Kinesis Data Streams** : data stream을 입력, 처리, 저장
  - **Kinesis Data Firehose** : data stream을 AWS 내부 또는 외부의 data store로 load
  - **Kinesis Data Analytics** : SQL 혹은 Apache Flink를 통해 data stream 분석
  - **Kinesis Video Streams** : video stream을 입력, 처리, 저장

### Kinesis Data Streams

- 시스템에 big data를 스트리밍하는 방법
- Shard
  - Kinesis Data Streams는 번호가 매겨진 여러 개의 shard로 구성됨
  - shard는 사전에 provisioning 되어야 함
  - 따라서 Kinesis Data Streams를 시작할 때 미리 몇 개의 shard가 있는 stream을 만들어야 함
  - 그러면 모든 shard에 데이터가 분할
  - shard는 수집 및 소비율에 맞춰 stream 용량 정의
- producers와 consumers가 Kinesis Data Streams를 사이에 두고 record를 활용해서 데이터를 주고받음

#### Properties

- 1일 ~ 365일의 retention 설정 가능
- 데이터를 reprocess할 수 있다는 뜻
- Kinesis에 삽입된 데이터는 삭제 불가 (immutability)
- 데이터를 보내면 partition key 추가
- 같은 partition key를 공유하는 메시지는 동일한 shard로 이동해서 key-based ordering을 제공

#### Capacity Modes

2개의 옵션

- **Provisioned mode**
  - 몇 개의 shard provisioned를 선택 후 수동으로 혹은 API를 사용해서 확장하는 것
  - 각 shard는 1MB/sec 또는 1,000 RPS(records per second)의 속도
  - classic 혹은 fan-out consumer의 경우 각 shard느 2MB/sec
  - pay per shard provisioned per hour
- **On-demand mode**
  - 용량을 프로비저닝하거나 관리할 필요가 없으며, 용량이 수요에 맞춰 자동 조정
  - default capacity provisioned: 4MB/sec 혹은 4,000 RPS
  - 지난 30일 간의 peak 처리량에 기반해서 auto scaling 수행
  - pay per stream per hour & data in/out per GB

→ 미리 용량이 예측되지 않는다면 on-demand mode를, 아니라면 provisioned mode를

#### Security

- IAM policies를 사용해서 shard 생성 및 읽기에 대한 access 제어 가능
- HTTPS endpoint를 이용한 encryption in flight
- KMS를 이용한 encryption at rest
- 클라이언트 측 암호화 (빡셈)
- VPC Endpoints도 Kinesis에 적용 가능
  - 인터넷을 거치지 않고 private subnet의 EC2 instance에서 Kinesis로 접근 가능
- 모든 API 호출을 CloudTrail을 통해 모니터링 가능

#### Producers

- data record를 data streams로 보냄
- data record consists of :
  - sequence number: shard의 partition key마다 고유
  - partition key: record를 stream에 넣을 때 반드시 지정해야 함
  - data blob: 최대 1MB
- producers can be :
  - AWS SDK: simple producer
  - Kinesis Producer Library (KPL)
    - C++, Java 등의 언어 지원
    - SDK 위에 구축
    - 배치, 압축, 재시도 등의 고급 기능을 API로 사용 가능
  - Kinesis Agent
    - KPL 위에 구축
    - monitor log files
- write throughput: 1MB/sec or 1,000 records/sec per shard
- PutRecord API
  - API의 배치를 이용하면 비용을 절감하고 처리량을 늘릴 수 있음
- "hot partition"을 피하기 위해 partition key를 잘 분배해야 함

#### Consumers

- data streams로부터 record를 가져오고 처리
- consumer can be :
  - AWS Lambda
  - Kinesis Data Analytics
  - Kinesis Data Firehose
  - Custom Consumer (AWS SDK) - Classic or Enhanced Fan-Out
  - Kinesis Client Library (KCL)

**Custom Consumer**

- Shared (Classic) Fan-out Consumer
  - 2MB/sec per shard across all consumers
  - GetRecord API 사용
    - Kinesis로부터 직접 데이터를 가져오는 API
    - 초당 최대 5번 호출 가능
  - pull model
  - 소비하는 애플리케이션이 적을 때 유용
  - latency 약 200ms
  - 비용 최소화 모델
  - 5초간 최대 10 MB 데이터 혹은 10,000 records 처리
- Enhanced Fan-out Consumer
  - 2MB/sec per consumer per shard
  - SubscribeToShard API 사용
  - push model
  - 같은 stream에 대한 multiple consuming applications
  - latency 약 70ms
    - shard 자체에서 데이터를 consumer에게 push하기 때문에 더 짧게 걸림
  - 비용이 더 들어감
  - HTTP/2 스트리밍 방식을 통해 데이터 push
  - soft limit of 5 consumer applications (KCL) per data stream
    - AWS에 티켓을 올려서 더 많은 consumer application 할당 가능

**AWS Lambda**

- Classic & Enhanced fan-out customer 모두 지원 가능
- 배치로 record를 읽을 수 있음
- 배치 크기 및 배치 영역 구성 가능
- 에러 발생 시 성공할 때까지 람다를 재시도하거나 데이터가 만료되도록
- 10 batches per shard simultaneously
